\section{Future Work}\label{sec:future-work}
\subsection{Minimise NBA}
\cite{fritz2002state, hopcroft1971n, kan2016partial}
\subsubsection{Reachability in Automata}
In the model-checking automata-based algorithm described in \autoref{sec:methods} two automata are used; GNBA and NBA. The size of the GNBA will directly impact the size of the NBA and the size of the NBA will directly impact the size of the product transition system $TS \otimes NBA$. 

Let us look at why the size of a NBA $A$ is affected by the size of a GNBA $\mathcal{G}$. The size of the NBA is $|\mathcal{A}| = \mathcal{O}(|\mathcal{G}| \cdot |\mathcal{F}|)$ where $\mathcal{F}$ denotes the set of acceptance sets in $\mathcal{G}$~\cite[thm. 4.56]{baier2008principles}. 
Not necessarily every state will be reachable from one of the initial states in the GNBA $\mathcal{G}=(Q,2^{AP},\delta,Q_0,\mathcal{F})$. A solution to identify this and narrow down $\mathcal{G}$ could be to create a copy of $\mathcal{G}$ called $\mathcal{G}'=(Q',2^{AP},\delta,Q_0,\mathcal{F}')$, where $Q' \subseteq Q$ and $\mathcal{F}' \subseteq \mathcal{F}$. $Q$ and $\mathcal{F}$ could be determined by performing a DFS from every state $q \in Q_0$. During a search for every state visited, if the state has been visited continue the search otherwise add it to $Q'$. Furthermore if the state is in a acceptance set add the set to $\mathcal{F}$ and continue the search. Doing so will give a GNBA $\mathcal{G}'$ that only contains reachable states and acceptance set, thus only the reachable states are transformed into an equivalent NBA.

\subsection{Caching of formula results}\label{sec:cache}
The current implementation does not perform any caching of whether or not policies holds under a data repository with respect to some data resource, that is for both confidentiality and integrity policies. The time complexity of the automata-based model-checking algorithm that was described in \autoref{sec:methods} is linear in the size of the transition system, i.e. the transformed data repository, and exponential in the length of the LTL formulae, i.e. the transformed PF~\cite{baier2008principles}. The most significant part here is the exponential growth in the length of the formulae. As the dependency tree\footnote{The tree that forms when following the dependencies of a data resource to their roots.} will only grow bigger as more resources are added the data repository, the time to determine if a inherited confidentiality policy holds will only increase. To overcome this caching could be introduced. As parts of the grammar in \autoref{tab:pf-grammar-user} have a strong relation to the data resource that is associated with the formulae as well as the subject of the context of execution, it is necessary to keep track of more information than just the results of the formulae being satisfied. The additional information includes the \emph{rsc} literal that is being putted or queried, the policy formula being either confidentiality or integrity, and \emph{usr} literal that is the subject of execution. This could form a sort of dictionary D, which could be defined as follows:
\begin{itemize}
    \item $D : R \times F \times U \rightharpoonup b$ is a partial mapping between data resources, policy formulae and \emph{usr} literals to \emph{bol} literals
\end{itemize}
After the first occurrence of the resource, policy and subject combination, the result will be cached for next time this exact combination occur. Using the proper data structure for this will allow constant time of the model-checking, as it will be a simple lookup.

\subsection{Minimise LTL formulae}
As mentioned in \autoref{sec:cache} the time complexity of the model-checking is exponential in the length of the LTL formulae, so a way to improve the performance of the system, is to construct an algorithm that reduces the length of LTL formulae. The algorithm could utilise the equivalence rules for LTL displayed in~\cite[Fig.~5.7]{baier2008principles} as well logical equivalence rules. Let us consider a small example where a UPF $\upf$ is constructed from the grammar in \autoref{tab:pf-grammar-user}. Note that it omits using expressions and functions, as they will be converted to atomic propositions when transforming UPF to IPF to LTL anyway and thus does not affect the length.
\begin{align*}
    \pf_u &\eqdef (a \imply b) \land (\lnot b \imply \G\F\G\G c)     \enskip &|\upf| = 8 & \\
    \pf_u &\eqdef (a \imply b) \land (\lnot b \imply \G\F\G c)       \enskip &|\upf| = 7 &\enskip \text{using idempotent laws} \\
    \pf_u &\eqdef (a \imply b) \land (\lnot b \imply \F\G c)         \enskip &|\upf| = 6 &\enskip \text{using absorption laws} \\
    \pf_u &\eqdef (\lnot a \lor b) \land (\lnot b \imply \F\G c)     \enskip &|\upf| = 7 &\enskip \text{using equivalence rules for implication} \\
    \pf_u &\eqdef (\lnot a \lor b) \land (\lnot \lnot b \lor \F\G c) \enskip &|\upf| = 8 &\enskip \text{using equivalence rules for implication} \\
    \pf_u &\eqdef (\lnot a \lor b) \land (b \lor \F\G c)             \enskip &|\upf| = 6 &\enskip \text{using double negation law} \\
    \pf_u &\eqdef b \lor (\lnot a \land \F\G c)                      \enskip &|\upf| = 5 &\enskip \text{using commutative and distributive laws}
\end{align*}
Let us call the expanded formulae for $\pf_{u_e}$. If we consider the length of the original formula $\upf$ and the expanded formula $\pf_{u_e}$ when their derived operators are replaced, i.e. \emph{implication}, \emph{or}, \emph{eventually} and \emph{always}, we get:
\begin{align}
    |\upf| = 18 \\
    |\pf_{u_e}| = 10
\end{align}
Another example and more simple example where no derived operators are used:
\begin{align*}
    \pf_{u_1} &\eqdef a \land a \land a \land a \land a \land a \land a \land a \land a \enskip &|\pf_{u_1}| = 8 & \\
    \pf_{u_1} &\eqdef a                                                                 \enskip &|\pf_{u_1}| = 1 &\enskip \text{using idempotent laws}
\end{align*}
From the two examples it is clear that there is some performance to gain, but it can be difficult to quantify exactly how much as the reduction of the length is very dependant on how the formulae are constructed.