\section{Introduction}
% What is the problem?
% Why is it useful
% Get the reader excited
% - Could consider to introduce the real world systems
% Make a citation for the github repo: https://zenodo.org/
Modern security principles serve to provide confidentiality and integrity of data but fail to maintain and control the propagation of information, which is commonly referred to as \emph{linkability} or \emph{provenance}. This paper investigates these properties by the creation of a graph-based data repository abstraction, with dependencies between data resources corresponding to their origins. Furthermore, we provide a model of confidentiality and integrity for data resources in the data repository. Confidentiality policies impose information flow constraints on the data resources to which they are associated and any data resource which depends on those resources. Integrity policies guarantee provenance insurance whenever resources are accessed in the repository. We introduce a provenance specification language to express confidentiality and integrity, called Policy Formulae (PF) based on Linear Temporal Logic (LTL). Instantiating the LTL grammar allows a straightforward approach of expressing properties of provenance in a data repository and to impose policies on data resources, as well as their dependencies. Examples of such properties, in this case in the form of integrity policies, could be the following:
\begin{itemize}
    \item (P1) \emph{``Was the resource of interest influenced by Alice without going through Mallory?''}
    \item (P2) \emph{``Was the resource of interest created by Alice and not influence by Mallory?''}
    \item (P3) \emph{``Was the resource of interest not influenced by Mallory unless it went through Alice?''}
\end{itemize}
In the proposed grammar the three properties would produce the following equivalent PF:
\begin{align*}
    \pf_{P1} &\eqdef author \neq user(Mallory) \U author = user(Alice) \\
    \pf_{P2} &\eqdef author = user(Alice) \land \G author \neq user(Mallory) \\
    \pf_{P3} &\eqdef \G author \neq user(Mallory) \lor author \neq user(Mallory) \U author = user(Alice)
\end{align*}
Let us illustrate the results of using the three integrity policies for querying data resources in a sample data repository. The data repository can be seen in \autoref{fig:intro}.
\begin{figure}[!ht]
    \begin{center}
        \input{figs/intro-example.tex}
        \caption{Sample data repository containing five data resources, their dependencies, attribute names and literals.}
        \label{fig:intro}
    \end{center}
\end{figure}
We introduce a model of computation, inspired by the model checking approach of BÃ¼chi automata, which for the domain of policy formulae computes the validity of such formulae given a data repository, a context of execution and a specific data resource. The model of computation produces the following results for the example PF:
\begin{itemize}
    \item $\pf_{P1}$ holds under $r_3$, $r_4$, $r_5$ but not otherwise
    \item $\pf_{P2}$ holds under $r_4$ but not otherwise
    \item $\pf_{P3}$ holds under $r_2$, $r_3$, $r_4$, $r_5$ but not otherwise
\end{itemize}

\paragraph{Contributions:} The four main contributions of this paper are as follows: (i) we instantiate the grammar for LTL to create a new grammar for PF that allows one to specify policies for data resources in a data repository, as well as a method for representing a PF as an LTL formula. (ii) We model a data repository with dependencies between data resources as a transition system. (iii) We offer a proof of concept implementation of the data repository in Google's programming language Go\footnote{\href{https://golang.org/}{https://golang.org/}}. Further details about the proof of concept implementation can be seen in \autoref{app:poc}. (iv) We present an algorithm for determining elementary sets of LTL formulae, which is a key computation step in the verification of the formulae. The algorithm's worst-case time complexity is no better than the naive approach but in practice, shows to be a significant improvement.

\paragraph{Paper Structure:}
The structure of the paper is as follows. First, related works are covered in \autoref{sec:related-works}. Then in \autoref{sec:preliminaries}, some preliminaries are introduced, including theory, terminology, and properties regarding LTL formulae. Next, the data repository is introduced in \autoref{sec:data-repository}, where the structure of the data repository and the operations to perform on the repository are shown. Furthermore, the grammar to construct policy formulae is covered as well as confidentiality and integrity policies. In \autoref{sec:methods} the parsing of policy formulae is described as well as the method used for verification of LTL formulae. This is followed by a discussion in~\autoref{sec:discussion}, where limitations of the new grammar are identified and discussed as well as some malicious behavior the data repository is vulnerable to. Finally, ideas for future work to the data repository are described in \autoref{sec:future-work}.